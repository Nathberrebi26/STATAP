# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cas8hrpw8oCIld6VejZMxNZKhSQvWfHa
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import PIL
import PIL.Image
from PIL import Image
import cv2 #conda install -c conda-forge opencv


import torchvision
import torch
import torch.utils.data
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor

from torchvision import datasets, models, transforms

def inference(list_path_inf, draw_bbox = True):
    list_images = []
    list_predictions = []
    for path_inf in list_path_inf:
        # # IF JPG : 
        # image = Image.open(path_inf) 
        # IF PNG 
        image = Image.open(path_inf).convert('RGB') # le .convert est NECESSAIRE pour les formats png

        img_array = np.array(image) # shape : (939, 805, 3)  # IF JPG : shape : (905, 662, 3)
        print(path_inf)
        if img_array.shape[2] == 3 : # IF JPG/PNG/JPEG
          data_transform = transforms.Compose([transforms.Resize((img_array.shape[0],img_array.shape[1] )), transforms.ToTensor()])

          image = data_transform(image).cuda() # donne une shape torch.Size([3, 905, 662])
          model.cuda()
          model.eval()
          out = model([image])
          list_images.append(image)
          list_predictions.append(out)

        #pour convert une image tensor AVEC CUDA to numpy il faut faire : img = image.cpu().numpy()
        # pour plot une image tenseur AVEC CUDA il faut faire : plt.imshow(image.cpu().permute(1,2,0))


        if draw_bbox == True : 
            plt.imshow(image.cpu().permute(1,2,0))
            box = out[0]['boxes']
            for i in range(len(box)):
                x_min ,y_min , x_max, y_max = box[i]
                plt.plot([x_min, x_max], [y_min,y_min], color = 'red', linestyle = 'solid')
                plt.plot([x_min, x_min], [y_min,y_max], color = 'red', linestyle = 'solid')
                plt.plot([x_max, x_max], [y_max, y_min], color = 'red', linestyle = 'solid')
                plt.plot([x_min, x_max ], [y_max, y_max], color = 'red', linestyle = 'solid')


            plt.axis('off')
            plt.show()
    return list_images, list_predictions

def compute_iou(box, boxes, box_area, boxes_area):
    
  """Calculates IoU of the given box with the array of the given boxes.
  box: 1D vector [y1, x1, y2, x2]
  boxes: [boxes_count, (y1, x1, y2, x2)]
  box_area: float. the area of 'box'
  boxes_area: array of length boxes_count.
  Note: the areas are passed in rather than calculated here for
  efficiency. Calculate once in the caller to avoid duplicate work.
  """

  # Calculate intersection areas

  y1 = np.maximum(box[0], boxes[:, 0])
  y2 = np.minimum(box[2], boxes[:, 2])
  x1 = np.maximum(box[1], boxes[:, 1])
  x2 = np.minimum(box[3], boxes[:, 3])
  intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)
  union = box_area + boxes_area[:] - intersection[:]
  iou = intersection / union
  return iou


def non_max_suppression(boxes, scores, threshold):
    """Performs non-maximum suppression and returns indices of kept boxes.
    boxes: [N, (y1, x1, y2, x2)]. Notice that (y2, x2) lays outside the box.
    scores: 1-D array of box scores.
    threshold: Float. IoU threshold to use for filtering.
    """
    try :
        boxes.shape[0] > 0


        # if boxes.dtype.kind != "f":
        #     boxes = boxes.astype(np.float32)

        # Compute box areas
        y1 = boxes[:, 0]
        x1 = boxes[:, 1]
        y2 = boxes[:, 2]
        x2 = boxes[:, 3]
        area = (y2 - y1) * (x2 - x1)

        # Get indicies of boxes sorted by scores (highest first)
        ixs = scores.argsort()
        ixs = ixs[::-1]

        pick = []
        while len(ixs) > 0:
          # Pick top box and add its index to the list
          i = ixs[0]
          pick.append(i)
          # Compute IoU of the picked box with the rest
          iou = compute_iou(boxes[i], boxes[ixs[1:]], area[i], area[ixs[1:]])
          # Identify boxes with IoU over the threshold. This
          # returns indices into ixs[1:], so add 1 to get
          # indices into ixs.
          remove_ixs = np.where(iou > threshold)[0] + 1
          # Remove indices of the picked and overlapped boxes.
          ixs = np.delete(ixs, remove_ixs)
          ixs = np.delete(ixs, 0)
        return np.array(pick, dtype=np.int32)
    except :
          print("Il n'y a pas de bbox dans cette image ")

def inference_NMS(path_image, model, threshold = 0.01):


  image = Image.open(path_image).convert('RGB')
  
  img_array = np.array(image) # shape : (939, 805, 3)
  data_transform = transforms.Compose([transforms.Resize((img_array.shape[0],img_array.shape[1] )), transforms.ToTensor()])
  image = data_transform(image).cuda() # donne une shape torch.Size([3, 905, 662])

  plt.figure(figsize=(25, 20))
  plt.subplot(131)
  plt.imshow(image.cpu().permute(1,2,0))

  model.cuda()
  model.eval()


  model.cuda()
  model.eval()

  with torch.no_grad(): out = model([image]) #model([img.to(device)])



  # Retrieve predicted bounding boxes and scores 
  boxes = out[0]['boxes'].cpu().numpy()
  scores = out[0]['scores'].cpu().numpy()

  # Plot predicted bouding boxes before and after NMS
  #plt.suptitle("Image {}    GT: {} - Prediction: {}".format(0, gt_label, pred_label), y=0.9, fontsize=18)
  plt.subplot(132)
  plt.title("Before NMS", fontsize=16)
  plt.axis('off')


  for i in range(len(boxes)):        

      plt.imshow(image.cpu().permute(1,2,0))

      box_label = len(out[0]['boxes'][i]) >= 0 

      x1,y1,x2,y2 = out[0]['boxes'][i]
      plt.plot([x1, x1, x2, x2, x1], [y1, y2, y2, y1, y1])


  kept_boxes = non_max_suppression(boxes, scores, threshold)
  plt.subplot(133)
  plt.title('After ', fontsize=16)
  plt.axis('off')
  for i in kept_boxes:        
      
      plt.imshow(image.cpu().permute(1, 2, 0))
      plt.plot([x1, x1, x2, x2, x1], [y1, y2, y2, y1, y1], 'r')

      #box_label = test2.id_class_dict[out[0]["labels"][i].item()]
      # if "NO" in box_label: c = "g-"
      # else: c = "r-"
      x1,y1,x2,y2 = out[0]['boxes'][i]
      plt.plot([x1, x1, x2, x2, x1], [y1, y2, y2, y1, y1])
  plt.show()

  return image, out


def inference_list_images_NMS(list_path_images, model, threshold = 0.01) : 
  list_predictions = []
  list_images_tensor = []
  
  for path_image in list_path_images : 
    image, prediction = inference_NMS(path_image, model, threshold)
    list_images_tensor.append(image)
    list_predictions.append(prediction)
  return list_images_tensor, list_predictions



def all_inference(list_path_images, path_to_model, n_classes=2, threshold = 0.5) :

  """
  Params : 
          list_path_images : la liste des chemins complets vers les images
          path_to_model:     le  chemin complet vers le model
  returns:
          dict_inference : dictionnaire ayant pour clé les indices de 0 à len(list_path_images), le chemin complet de l'image, et le dictionnaire de prédicitons
  """
  
  image_mean = (0.94103664, 0.9415971, 0.94051343)
  image_std = (0.03799264, 0.03603894, 0.03942578)


  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True,
                                                          image_mean=image_mean,
                                                          image_std=image_std)
  # original number of features in classifier head
  in_features = model.roi_heads.box_predictor.cls_score.in_features
  # adapting number of classes
  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, n_classes)

  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
  #print(f'Device: {device}')
  optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
  model.to(device)

  model.load_state_dict(torch.load(path_to_model))

  list_images_tensor, list_predictions = inference_list_images_NMS(list_path_images, model, threshold)

  dict_inference = {id : {"image_path" : list_path_images[id], "image" : img, "prediction" : list_predictions[id]} for id,img in enumerate(list_images_tensor)}

  return dict_inference